{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b27c961-eefc-4386-82df-3dc45ca40556",
   "metadata": {},
   "source": [
    "# JACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714231df-42c1-4840-b033-9da6c43b27a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_distance\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'analysis'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from analysis import calculate_distance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# For KELP\n",
    "class ModelCreator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.data = pd.read_csv(\"kelp.csv\")\n",
    "        self.data.columns = self.data.columns.str.strip()  # Clean up any whitespace\n",
    "\n",
    "        self.data[\"mid_price\"] = (self.data[\"bid_price_1\"] + self.data[\"ask_price_1\"]) / 2\n",
    "\n",
    "        # steven imbalance metric\n",
    "        imbalance = []  # imbalance = sum(for all levels)((1/(midpoint-level.price))*level.volume)\n",
    "        for index, row in self.data.iterrows():\n",
    "            total_imbalance = 0.0\n",
    "            for i in range(1, 4, 1):\n",
    "                for side in [\"bid\", \"ask\"]:\n",
    "                    price = row[f\"{side}_price_{i}\"]\n",
    "\n",
    "                    if not pd.isna(price):\n",
    "                        volume = row[f\"{side}_volume_{i}\"]\n",
    "                        dist = row[\"mid_price\"] - price\n",
    "                        total_imbalance += (1 / dist) * volume  # 'Top level more significant'\n",
    "\n",
    "            imbalance.append(total_imbalance)\n",
    "\n",
    "        self.data[\"imbalance\"] = imbalance\n",
    "\n",
    "        # log return\n",
    "        # shift(1) moves the previous row's value forward. so therefore here logreturn[i] = logreturn from row i-1 to row i\n",
    "        for dt in range(1, self.lookback + 1, 1):\n",
    "            self.data[f\"log_return_{dt}\"] = np.log(self.data[\"mid_price\"] / self.data[\"mid_price\"].shift(dt)).fillna(0)\n",
    "\n",
    "        # volatility (is this even relevant)\n",
    "        self.data[\"volatility_10\"] = self.data[\"log_return_1\"].rolling(10).std()\n",
    "\n",
    "        # momentum\n",
    "        self.data[\"momentum_5\"] = self.data[\"mid_price\"].rolling(5).mean()\n",
    "\n",
    "    def run_regression(self, lookahead=5, lookback=5, train_ratio=0.8, debug=False):\n",
    "        self.lookback = lookback  # uses log returns from t-1, t-2,... t-lookback\n",
    "        self.preprocess()\n",
    "\n",
    "        # Target: future log return (t+lookahead)\n",
    "        # shift(-lookahead) means target[i] gives the logreturn from t to t+lookahead\n",
    "        self.data[\"target\"] = np.log(self.data[\"mid_price\"].shift(-lookahead) / self.data[\"mid_price\"])\n",
    "        self.data.dropna(subset=[\"target\"], inplace=True)  # dropna for y\n",
    "\n",
    "        # Features\n",
    "        features = [\"imbalance\", \"volatility_10\", \"momentum_5\"] + [f\"log_return_{dt}\" for dt in range(1, self.lookback + 1)]\n",
    "        self.data.dropna(subset=features, inplace=True)  # dropna for X\n",
    "        X = self.data[features]\n",
    "        y = self.data[\"target\"]\n",
    "\n",
    "        # attempt: to use polynomial features\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        # Train/test split to prevent lookahead bias\n",
    "        split_idx = int(len(self.data) * train_ratio)\n",
    "        X_train, X_test = X_poly[:split_idx], X_poly[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "        # Fit model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        if debug:\n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Metrics\n",
    "            print(f\"Lookahead: {lookahead}\")\n",
    "\n",
    "            train_r2 = r2_score(y_train, model.predict(X_train))\n",
    "            train_mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "            print(f\"Training r2: {train_r2:.4f}\")\n",
    "            print(f\"Training MSE: {train_mse:.8f}\")  # these will be very small, (not because its accurate) but because logreturns are just very small\n",
    "\n",
    "            test_r2 = r2_score(y_test, y_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "            print(f\"Test r2: {test_r2:.4f}\")\n",
    "            print(f\"MSE: {test_mse:.8f}\")  # these will be very small, (not because its accurate) but because logreturns are just very small\n",
    "\n",
    "            print(\"Intercept:\", model.intercept_)\n",
    "            print(\"Coefficients: \")\n",
    "\n",
    "            # for debugging, i wanna see what features are important (after poly transformation)\n",
    "            coeffs = list(zip(poly.get_feature_names_out(input_features=X.columns), model.coef_))\n",
    "\n",
    "            # Sort by absolute value (importance)\n",
    "            sorted_coeffs = sorted(coeffs, key=lambda x: abs(x[1]), reverse=True)\n",
    "            print(\"Top polynomial features by importance:\")\n",
    "            for name, value in sorted_coeffs[:100]:\n",
    "                print(f\"{name}: {value:.6f}\")\n",
    "\n",
    "            # Plot predicted vs actual\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(y_test.values, label=\"Actual\", alpha=0.7)\n",
    "            plt.plot(y_pred, label=\"Predicted\", alpha=0.7)\n",
    "            plt.legend()\n",
    "            plt.title(f\"Log Return Prediction (lookahead={lookahead})\")\n",
    "            plt.xlabel(\"Time Index\")\n",
    "            plt.ylabel(\"Log Return\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return model.predict(X_poly)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # model = creator.run_regression(lookahead=2, lookback=5, train_ratio=0.8)\n",
    "\n",
    "    mid_prices = None\n",
    "\n",
    "    predictions: dict[int, LinearRegression] = {}\n",
    "    min_lookahead = 1\n",
    "    max_lookahead = 10\n",
    "    for lookahead in range(min_lookahead, max_lookahead + 1, 1):\n",
    "        creator = ModelCreator()\n",
    "        predictions[lookahead] = creator.run_regression(lookahead=lookahead, lookback=5, train_ratio=0.8)\n",
    "        print(\"done\")\n",
    "\n",
    "        mid_prices = creator.data[\"mid_price\"].to_numpy()\n",
    "\n",
    "    # Start figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(mid_prices, label=\"Actual Price\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "    for i in range(len(mid_prices) - max_lookahead):\n",
    "        base_price = mid_prices[i]\n",
    "\n",
    "        # Predicted future prices using log return\n",
    "        predicted_prices = [base_price * np.exp(predictions[k][i]) for k in range(1, max_lookahead + 1)]\n",
    "\n",
    "        # X-values for predicted points\n",
    "        x_values = list(range(i, i + max_lookahead + 1))\n",
    "        y_values = [base_price] + predicted_prices\n",
    "\n",
    "        # Plot the predicted line from point i\n",
    "        plt.plot(x_values, y_values, color=\"blue\", alpha=0.3)\n",
    "\n",
    "    plt.title(\"Multi-Step Forecasts from Each Time Point\")\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.ylabel(\"Mid Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # bro this model is so shit R^2 is like 0.25\n",
    "    # i think its because its not linearly correlated or smth idk\n",
    "    # or maybe im just not using enough indicators\n",
    "    # im using like last 10 steps of log return but those are just the exact same thing\n",
    "    # maybe i need some other indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66055c77-0f12-4f1b-8a1c-6b77fd666e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
