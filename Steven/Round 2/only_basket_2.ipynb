{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9279142a",
   "metadata": {},
   "source": [
    "# Guide on how to use the backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a715a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the project root is in PATH.\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# All imports of our code are relative to the project root.\n",
    "\n",
    "from backtester.backtester import Backtester\n",
    "from backtester.datamodel import TradingState, OrderDepth, Order, Listing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a2c5b",
   "metadata": {},
   "source": [
    "This is the implementation of our trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c749aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Trader:\n",
    "\n",
    "    kelp_df = pd.DataFrame(columns=[\n",
    "        \"timestamp\", \"product\",\n",
    "        \"bid_price_1\", \"bid_volume_1\", \"bid_price_2\", \"bid_volume_2\", \"bid_price_3\", \"bid_volume_3\",\n",
    "        \"ask_price_1\", \"ask_volume_1\", \"ask_price_2\", \"ask_volume_2\", \"ask_price_3\", \"ask_volume_3\",\n",
    "        \"mid_price\", \"profit_and_loss\"\n",
    "    ])\n",
    "\n",
    "    resin_df = pd.DataFrame(columns=[\n",
    "        \"timestamp\", \"product\",\n",
    "        \"bid_price_1\", \"bid_volume_1\", \"bid_price_2\", \"bid_volume_2\", \"bid_price_3\", \"bid_volume_3\",\n",
    "        \"ask_price_1\", \"ask_volume_1\", \"ask_price_2\", \"ask_volume_2\", \"ask_price_3\", \"ask_volume_3\",\n",
    "        \"mid_price\", \"profit_and_loss\"\n",
    "    ])\n",
    "\n",
    "    squink_df = pd.DataFrame(columns=[\n",
    "        \"timestamp\", \"product\",\n",
    "        \"bid_price_1\", \"bid_volume_1\", \"bid_price_2\", \"bid_volume_2\", \"bid_price_3\", \"bid_volume_3\",\n",
    "        \"ask_price_1\", \"ask_volume_1\", \"ask_price_2\", \"ask_volume_2\", \"ask_price_3\", \"ask_volume_3\",\n",
    "        \"mid_price\", \"profit_and_loss\"\n",
    "    ])\n",
    "    # “If none of the bots trade on an outstanding player quote, the quote is automatically cancelled at the end of the iteration.”\n",
    "\n",
    "    def update_df(df, product, state, orders, order_depth):\n",
    "        buy_orders = sorted(order_depth.buy_orders.items(), key=lambda x: -x[0])\n",
    "        sell_orders = sorted(order_depth.sell_orders.items(), key=lambda x: x[0])\n",
    "\n",
    "        bid_levels = buy_orders[:3] + [(None, None)] * (3 - len(buy_orders))\n",
    "        ask_levels = sell_orders[:3] + [(None, None)] * (3 - len(sell_orders))\n",
    "\n",
    "        if bid_levels[0][0] is not None and ask_levels[0][0] is not None:\n",
    "            mid_price = (bid_levels[0][0] + ask_levels[0][0]) / 2\n",
    "        else:\n",
    "            mid_price = None\n",
    "\n",
    "        row = {\n",
    "            \"timestamp\": state.timestamp,\n",
    "            \"product\": product,\n",
    "            \"bid_price_1\": bid_levels[0][0], \"bid_volume_1\": bid_levels[0][1],\n",
    "            \"bid_price_2\": bid_levels[1][0], \"bid_volume_2\": bid_levels[1][1],\n",
    "            \"bid_price_3\": bid_levels[2][0], \"bid_volume_3\": bid_levels[2][1],\n",
    "            \"ask_price_1\": ask_levels[0][0], \"ask_volume_1\": ask_levels[0][1],\n",
    "            \"ask_price_2\": ask_levels[1][0], \"ask_volume_2\": ask_levels[1][1],\n",
    "            \"ask_price_3\": ask_levels[2][0], \"ask_volume_3\": ask_levels[2][1],\n",
    "            \"mid_price\": mid_price,\n",
    "        }\n",
    "\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "\n",
    "\n",
    "    def run(self, state: TradingState):\n",
    "        # Only method required. It takes all buy and sell orders for all symbols as an input, and outputs a list of orders to be sent\n",
    "\n",
    "        result = {}\n",
    "        for product in state.order_depths:\n",
    "            order_depth: OrderDepth = state.order_depths[product]\n",
    "            orders: List[Order] = []\n",
    "            # Basket 2 is 4 croissants, 2 jams\n",
    "            synthetic_bid = 0\n",
    "            synthetic_offer = 0\n",
    "            if product == \"CROISSANT\":\n",
    "                if len(order_depth.sell_orders) != 0 and len(order_depth.buy_orders) != 0:\n",
    "                    best_ask_croissant, best_ask_amount_croissant = list(order_depth.sell_orders.items())[0]\n",
    "                    best_bid_croissant, best_bid_amount_croissant = list(order_depth.buy_orders.items())[0]\n",
    "                    synthetic_bid += best_bid_croissant * 4\n",
    "                    synthetic_offer += best_ask_croissant * 2\n",
    "\n",
    "                    \n",
    "            if product == \"JAMS\":\n",
    "                if len(order_depth.sell_orders) != 0 and len(order_depth.buy_orders) != 0:\n",
    "                    best_ask_jam, best_ask_amount_jam = list(order_depth.sell_orders.items())[0]\n",
    "                    best_bid_jam, best_bid_amount_jam = list(order_depth.buy_orders.items())[0]\n",
    "                    synthetic_bid += best_bid_jam * 2\n",
    "                    synthetic_offer += best_ask_jam * 2\n",
    "\n",
    "            if product == 'PICNIC_BASKET_2':\n",
    "                if len(order_depth.sell_orders) != 0 and len(order_depth.buy_orders) != 0:\n",
    "                    best_ask, best_ask_amount = list(order_depth.sell_orders.items())[0]\n",
    "                    best_bid, best_bid_amount = list(order_depth.buy_orders.items())[0]\n",
    "\n",
    "                    if best_ask < synthetic_bid:\n",
    "                        orders.append(Order('PICNIC_BASKET_2', best_ask, 1)) \n",
    "                        orders.append(Order('JAM', best_bid_jam, -2)) \n",
    "                        orders.append(Order('CROISSANT', best_bid_croissant, -4)) \n",
    "                    elif best_bid > synthetic_offer:\n",
    "                        orders.append(Order('PICNIC_BASKET_2', best_bid, -1)) \n",
    "                        orders.append(Order('JAM', best_ask_jam, 2)) \n",
    "                        orders.append(Order('CROISSANT', best_ask_croissant, 4)) \n",
    "                        \n",
    "\n",
    "                result[product] = orders\n",
    "                print(orders)\n",
    "\n",
    "        traderData = \"SAMPLE\"  # String value holding Trader state data required. It will be delivered as TradingState.traderData on next execution.\n",
    "\n",
    "        conversions = 1\n",
    "        return result, conversions, traderData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8687284",
   "metadata": {},
   "source": [
    "Copy paste these below lines whenever you want to access the historical data. These have datatype `pd.Dataframe`.  \n",
    "\n",
    "If you want all 3 days combined into 1, then copy the code for `market_data_all3days` and `trades_all3days`. You can't just `pd.concat()` them all because the backtester doesn't consider day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a26b20d-1298-417e-8f64-f74638776971",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/round2/prices_round_2_day_-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m market_data_round_2_day_neg1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_-1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m market_data_round_2_day_0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m market_data_round_2_day_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/round2/prices_round_2_day_-1.csv'"
     ]
    }
   ],
   "source": [
    "market_data_round_2_day_neg1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_-1.csv\"), sep=\";\")\n",
    "market_data_round_2_day_0 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_0.csv\"), sep=\";\")\n",
    "market_data_round_2_day_1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_1.csv\"), sep=\";\")\n",
    "\n",
    "trades_round_2_day_neg1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_-1.csv\"), sep=\";\")\n",
    "trades_round_2_day_0 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_0.csv\"), sep=\";\")\n",
    "trades_round_2_day_1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_1.csv\"), sep=\";\")\n",
    "\n",
    "\n",
    "market_data_round_2_all3days = concatenate_historical_data([market_data_round_2_day_neg1, market_data_round_2_day_0, market_data_round_2_day_1])\n",
    "trades_round_2_all3days = concatenate_historical_data([trades_round_2_day_neg1, trades_round_2_day_0, trades_round_2_day_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6092f218",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/round2/prices_round_2_day_-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m market_data_day_0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_-1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m market_data_day_neg1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m market_data_day_neg2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprices_round_2_day_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/round2/prices_round_2_day_-1.csv'"
     ]
    }
   ],
   "source": [
    "market_data_day_0 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_-1.csv\"), sep=\";\")\n",
    "market_data_day_neg1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_0.csv\"), sep=\";\")\n",
    "market_data_day_neg2 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"prices_round_2_day_1.csv\"), sep=\";\")\n",
    "\n",
    "trades_day_0 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_-1.csv\"), sep=\";\")\n",
    "trades_day_neg1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_0.csv\"), sep=\";\")\n",
    "trades_day_neg2 = pd.read_csv(os.path.join(\"..\", \"data\", \"round2\", \"trades_round_2_day_1.csv\"), sep=\";\")\n",
    "\n",
    "\n",
    "# concatenates multiple days of historical data into 1.\n",
    "# drops day column and replaces it with continuous timestamps.\n",
    "# i.e. day -1 timestamp 0 becomes just timestamp 1,000,000\n",
    "def concatenate_historical_data(data: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    output = data[0]\n",
    "\n",
    "    for i in range(1, len(data), 1):\n",
    "        timeshift = output.iloc[-1][\"timestamp\"] + 100  # 100 for next day\n",
    "        next_day_copy = data[i].copy()\n",
    "        next_day_copy[\"timestamp\"] += timeshift\n",
    "\n",
    "        output = pd.concat([output, next_day_copy])\n",
    "\n",
    "    return output\n",
    "\n",
    "market_data_all3days = concatenate_historical_data([market_data_day_neg2, market_data_day_neg1, market_data_day_0])\n",
    "trades_all3days = concatenate_historical_data([trades_day_neg2, trades_day_neg1, trades_day_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612809cc",
   "metadata": {},
   "source": [
    "Lets run the backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e4cd6ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'market_data_day_neg1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 4. Market data and trade history files.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# These already exist, look at the previous jupyter cell.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 5. Instantiate trader object\u001b[39;00m\n\u001b[1;32m     31\u001b[0m trader \u001b[38;5;241m=\u001b[39m Trader()\n\u001b[0;32m---> 32\u001b[0m bt \u001b[38;5;241m=\u001b[39m Backtester(trader, listings, position_limit, fair_value_evaluator, market_data_day_neg1, trades_day_neg1, output_log_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteven.log\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m bt\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(bt\u001b[38;5;241m.\u001b[39mpnl)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'market_data_day_neg1' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Define the listings.\n",
    "listings = {\n",
    "    \"KELP\": Listing(symbol=\"KELP\", product=\"KELP\", denomination=\"SEASHELLS\"),\n",
    "    \"RAINFOREST_RESIN\": Listing(symbol=\"RAINFOREST_RESIN\", product=\"RAINFOREST_RESIN\", denomination=\"SEASHELLS\"),\n",
    "    \"SQUID_INK\": Listing(symbol=\"SQUID_INK\", product=\"SQUID_INK\", denomination=\"SEASHELLS\"),\n",
    "}\n",
    "\n",
    "# 2. Define the position limits.\n",
    "position_limit = {\n",
    "    \"KELP\": 50,\n",
    "    \"RAINFOREST_RESIN\": 50,\n",
    "    \"SQUID_INK\": 50,\n",
    "}\n",
    "\n",
    "\n",
    "# 3. Define fair value evaluation functions. This is used to determine what our PNL is at times throughout execution when our net position is not 0.\n",
    "def calc_rainforest_resin_fair(order_depth: OrderDepth) -> float:\n",
    "    return 10000\n",
    "\n",
    "\n",
    "fair_value_evaluator = {\n",
    "    # omitting dictionary entries for KELP, SQUID_INK, so that they use default behaviour: fair_price = (best_bid+best_ask)/2\n",
    "    \"RAINFOREST_RESIN\": calc_rainforest_resin_fair,\n",
    "}\n",
    "\n",
    "\n",
    "# 4. Market data and trade history files.\n",
    "# These already exist, look at the previous jupyter cell.\n",
    "\n",
    "# 5. Instantiate trader object\n",
    "trader = Trader()\n",
    "bt = Backtester(trader, listings, position_limit, fair_value_evaluator, market_data_day_neg1, trades_day_neg1, output_log_filename=\"steven.log\")\n",
    "\n",
    "\n",
    "bt.run()\n",
    "\n",
    "print(bt.pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90cc33ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m    \n\u001b[1;32m      2\u001b[0m product \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQUID_INK\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m resin_metrics \u001b[38;5;241m=\u001b[39m bt\u001b[38;5;241m.\u001b[39mcalculate_metrics(product)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPNL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbt\u001b[38;5;241m.\u001b[39mpnl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMidpoint Sharpe: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresin_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidpoint_sharpe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt    \n",
    "product = \"SQUID_INK\"\n",
    "\n",
    "resin_metrics = bt.calculate_metrics(product)\n",
    "print(f\"PNL: {bt.pnl}\")\n",
    "\n",
    "print(f\"Midpoint Sharpe: {resin_metrics['midpoint_sharpe']:.4f}\")\n",
    "print(f\"Spreadcrossing Sharpe: {resin_metrics['spreadcrossing_sharpe']:.4f}\")\n",
    "print(f\"Midpoint PnL (bps): {resin_metrics['midpoint_pnl_bps']:.2f}\")\n",
    "print(f\"Spreadcrossing PnL (bps): {resin_metrics['spreadcrossing_pnl_bps']:.2f}\")\n",
    "\n",
    "# THIS PART PLOTS SPREADCROSSING_PNL AND MIDPOINT_PNL\n",
    "spreadcrossing_pnl_history = bt.get_metric(\"spreadcrossing_pnl\", product)\n",
    "midpoint_pnl_history = bt.get_metric(\"midpoint_pnl\", product)\n",
    "timestamps = np.unique(bt.market_data[\"timestamp\"])\n",
    "\n",
    "plt.plot(timestamps, spreadcrossing_pnl_history, label=\"Spreadcrossing PnL\", color=\"blue\")\n",
    "plt.plot(timestamps, midpoint_pnl_history, label=\"Midpoint PnL\", color=\"orange\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"PnL\")\n",
    "plt.title(\"Spread Crossing vs Midpoint PnL Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a831e9",
   "metadata": {},
   "source": [
    "You can copy paste everything, except for the Trader algo, which should be whatever algo you wish to backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab01c2b-9584-494a-8436-1365b4bf10d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95bbdb-aba2-4f11-8755-a453048633d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dad69-b539-4678-bebf-ae115c71c526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
