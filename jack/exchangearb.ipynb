{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39aa3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the project root is in PATH.\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "# All imports of our code are relative to the project root.\n",
    "\n",
    "from backtester.engine import Backtester\n",
    "from backtester.datamodel import TradingState, OrderDepth, Order, Listing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# concatenates multiple days of historical data into 1.\n",
    "# drops day column and replaces it with continuous timestamps.\n",
    "# i.e. day -1 timestamp 0 becomes just timestamp 1,000,000\n",
    "def concatenate_historical_data(data: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    output = data[0]\n",
    "\n",
    "    for i in range(1, len(data), 1):\n",
    "        timeshift = output.iloc[-1][\"timestamp\"] + 100  # 100 for next day\n",
    "        next_day_copy = data[i].copy()\n",
    "        next_day_copy[\"timestamp\"] += timeshift\n",
    "\n",
    "        output = pd.concat([output, next_day_copy])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_round_4_day_1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"prices_round_4_day_1.csv\"), sep=\";\")\n",
    "market_data_round_4_day_2 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"prices_round_4_day_2.csv\"), sep=\";\")\n",
    "market_data_round_4_day_3 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"prices_round_4_day_3.csv\"), sep=\";\")\n",
    "\n",
    "trades_round_4_day_1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"trades_round_4_day_1.csv\"), sep=\";\")\n",
    "trades_round_4_day_2 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"trades_round_4_day_2.csv\"), sep=\";\")\n",
    "trades_round_4_day_3 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"trades_round_4_day_3.csv\"), sep=\";\")\n",
    "\n",
    "observations_round_4_day_1 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"observations_round_4_day_1.csv\"), sep=\",\")\n",
    "observations_round_4_day_2 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"observations_round_4_day_2.csv\"), sep=\",\")\n",
    "observations_round_4_day_3 = pd.read_csv(os.path.join(\"..\", \"data\", \"round4\", \"observations_round_4_day_3.csv\"), sep=\",\")\n",
    "\n",
    "market_data_round_4_all3days = concatenate_historical_data([market_data_round_4_day_1, market_data_round_4_day_2, market_data_round_4_day_3])\n",
    "trades_round_4_all3days = concatenate_historical_data([trades_round_4_day_1, trades_round_4_day_2, trades_round_4_day_3])\n",
    "observations_round_4_all3days = concatenate_historical_data([observations_round_4_day_1, observations_round_4_day_2, observations_round_4_day_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGNIFICENT_MACARONS = \"MAGNIFICENT_MACARONS\"\n",
    "\n",
    "\n",
    "def get_time_part(df: pd.DataFrame, l, h) -> pd.DataFrame:\n",
    "    dfret = df.copy()\n",
    "    dfret = dfret[(dfret[\"timestamp\"] >= l) & (dfret[\"timestamp\"] < h)].reset_index(drop=True)\n",
    "    return dfret\n",
    "\n",
    "\n",
    "def get_sunlight_part(\n",
    "    md: pd.DataFrame, th: pd.DataFrame, obs: pd.DataFrame, low: float, high: float\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Return three DataFrames (md_slice, th_slice, obs_slice) containing\n",
    "    only the rows whose timestamps fall into the obs rows where\n",
    "    sunlightIndex is in [low, high).\n",
    "    \"\"\"\n",
    "    # 1) find all timestamps where sunlight is in the desired band\n",
    "    mask = (obs[\"sunlightIndex\"] >= low) & (obs[\"sunlightIndex\"] < high)\n",
    "    ts = obs.loc[mask, \"timestamp\"]\n",
    "\n",
    "    # 2) slice each DataFrame by those timestamps\n",
    "    md_slice = md[md[\"timestamp\"].isin(ts)].reset_index(drop=True)\n",
    "    th_slice = th[th[\"timestamp\"].isin(ts)].reset_index(drop=True)\n",
    "    obs_slice = obs.loc[mask].reset_index(drop=True)\n",
    "\n",
    "    return md_slice, th_slice, obs_slice\n",
    "\n",
    "\n",
    "md_all = market_data_round_4_all3days.copy()\n",
    "th_all = trades_round_4_all3days.copy()\n",
    "obs_all = observations_round_4_all3days.copy()\n",
    "\n",
    "md_all = md_all[md_all[\"product\"] == MAGNIFICENT_MACARONS]\n",
    "th_all = th_all[th_all[\"symbol\"] == MAGNIFICENT_MACARONS]\n",
    "\n",
    "\n",
    "l, h = 0, 3e6\n",
    "md_all = get_time_part(md_all, l, h)\n",
    "th_all = get_time_part(th_all, l, h)\n",
    "obs_all = get_time_part(obs_all, l, h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98368a5d",
   "metadata": {},
   "source": [
    "### First lets try split the data into regimes \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d787c",
   "metadata": {},
   "source": [
    "Regime splitting: By sunlight value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1879568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sunlight_thresh1 = 37\n",
    "# sunlight_thresh2 = 54\n",
    "\n",
    "# md_regime1, th_regime1, obs_regime1 = get_sunlight_part(md_all, th_all, obs_all, 0, sunlight_thresh1)\n",
    "# md_regime2, th_regime2, obs_regime2 = get_sunlight_part(md_all, th_all, obs_all, sunlight_thresh1, sunlight_thresh2)\n",
    "# md_regime3, th_regime3, obs_regime3 = get_sunlight_part(md_all, th_all, obs_all, sunlight_thresh2, 99999)\n",
    "\n",
    "\n",
    "# mds = [md_regime1, md_regime2, md_regime3]\n",
    "# ths = [th_regime1, th_regime2, th_regime3]\n",
    "# obss = [obs_regime1, obs_regime2, obs_regime3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edec2b4",
   "metadata": {},
   "source": [
    "Regime splitting: by each piecewise part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7864b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# md_regime1 = get_time_part(md_all, 0, 2e5)\n",
    "# th_regime1 = get_time_part(th_all, 0, 2e5)\n",
    "# obs_regime1 = get_time_part(obs_all, 0, 2e5)\n",
    "\n",
    "# md_regime2 = get_time_part(md_all, 2e5, 4e5)\n",
    "# th_regime2 = get_time_part(th_all, 2e5, 4e5)\n",
    "# obs_regime2 = get_time_part(obs_all, 2e5, 4e5)\n",
    "\n",
    "# md_regime3 = get_time_part(md_all, 4e5, 5e5)\n",
    "# th_regime3 = get_time_part(th_all, 4e5, 5e5)\n",
    "# obs_regime3 = get_time_part(obs_all, 4e5, 5e5)\n",
    "\n",
    "# md_regime4 = get_time_part(md_all, 5e5, 6e5)\n",
    "# th_regime4 = get_time_part(th_all, 5e5, 6e5)\n",
    "# obs_regime4 = get_time_part(obs_all, 5e5, 6e5)\n",
    "\n",
    "# md_regime5 = get_time_part(md_all, 6e5, 7e5)\n",
    "# th_regime5 = get_time_part(th_all, 6e5, 7e5)\n",
    "# obs_regime5 = get_time_part(obs_all, 6e5, 7e5)\n",
    "\n",
    "# md_regime6 = get_time_part(md_all, 7e5, 9e5)\n",
    "# th_regime6 = get_time_part(th_all, 7e5, 9e5)\n",
    "# obs_regime6 = get_time_part(obs_all, 7e5, 9e5)\n",
    "\n",
    "# md_regime7 = get_time_part(md_all, 9e5, 10e5)\n",
    "# th_regime7 = get_time_part(th_all, 9e5, 10e5)\n",
    "# obs_regime7 = get_time_part(obs_all, 9e5, 10e5)\n",
    "\n",
    "# mds = [md_regime1, md_regime2, md_regime3, md_regime4, md_regime5, md_regime6, md_regime7]\n",
    "# ths = [th_regime1, th_regime2, th_regime3, th_regime4, th_regime5, th_regime6, th_regime7]\n",
    "# obss = [obs_regime1, obs_regime2, obs_regime3, obs_regime4, obs_regime5, obs_regime6, obs_regime7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279821cf",
   "metadata": {},
   "source": [
    "Regime splitting: by up/down/flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e4a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# up\n",
    "md_regime1 = pd.concat([get_time_part(md_all, 0, 2e5), get_time_part(md_all, 4e5, 5e5), get_time_part(md_all, 9e5, 10e5)], ignore_index=True)\n",
    "th_regime1 = pd.concat([get_time_part(th_all, 0, 2e5), get_time_part(th_all, 4e5, 5e5), get_time_part(th_all, 9e5, 10e5)], ignore_index=True)\n",
    "obs_regime1 = pd.concat([get_time_part(obs_all, 0, 2e5), get_time_part(obs_all, 4e5, 5e5), get_time_part(obs_all, 9e5, 10e5)], ignore_index=True)\n",
    "\n",
    "# down\n",
    "md_regime2 = pd.concat([get_time_part(md_all, 2e5, 4e5), get_time_part(md_all, 6e5, 7e5)], ignore_index=True)\n",
    "th_regime2 = pd.concat([get_time_part(th_all, 2e5, 4e5), get_time_part(th_all, 6e5, 7e5)], ignore_index=True)\n",
    "obs_regime2 = pd.concat([get_time_part(obs_all, 2e5, 4e5), get_time_part(obs_all, 6e5, 7e5)], ignore_index=True)\n",
    "\n",
    "# flat\n",
    "md_regime3 = pd.concat([get_time_part(md_all, 5e5, 6e5), get_time_part(md_all, 7e5, 9e5)], ignore_index=True)\n",
    "th_regime3 = pd.concat([get_time_part(th_all, 5e5, 6e5), get_time_part(th_all, 7e5, 9e5)], ignore_index=True)\n",
    "obs_regime3 = pd.concat([get_time_part(obs_all, 5e5, 6e5), get_time_part(obs_all, 7e5, 9e5)], ignore_index=True)\n",
    "\n",
    "mds = [md_regime1, md_regime2, md_regime3]\n",
    "ths = [th_regime1, th_regime2, th_regime3]\n",
    "obss = [obs_regime1, obs_regime2, obs_regime3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6173b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 opportunities for arb 1\n",
      "Max profit: 2461.7999999999856\n",
      "6.593846153846154\n",
      "0 opportunities for arb 2\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "md = get_time_part(md_all, 0, 1e6)  # 2e5)\n",
    "th = get_time_part(th_all, 0, 1e6)  # 2e5)\n",
    "obs = get_time_part(obs_all, 0, 1e6)  # 2e5)\n",
    "\n",
    "\n",
    "obs[\"actual_ask\"] = obs[\"askPrice\"] + obs[\"transportFees\"] + obs[\"importTariff\"]\n",
    "obs[\"actual_bid\"] = obs[\"bidPrice\"] - obs[\"transportFees\"] - obs[\"exportTariff\"]\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(md['timestamp'], md['bid_price_1'],label = 'bid_price_1')\n",
    "# plt.plot(md['timestamp'], obs['actual_ask'],label='actual_ask')\n",
    "# plt.plot(md['timestamp'], md['bid_price_1'],label='bid_price_1')\n",
    "# plt.plot(md['timestamp'], md['ask_price_1'],label='ask_price_1')\n",
    "# plt.plot(md['timestamp'], md['bid_price_2'],label='bid_price_2')\n",
    "# plt.plot(md['timestamp'], md['ask_price_2'],label='ask_price_2')\n",
    "# plt.plot(md['timestamp'], md['bid_price_3'],label='bid_price_3')\n",
    "# plt.plot(md['timestamp'], md['ask_price_3'],label='ask_price_3')\n",
    "\n",
    "# plt.plot(obs['timestamp'], obs['actual_ask'],label='actual_ask_chefs')\n",
    "# plt.plot(obs['timestamp'], obs['actual_bid'],label='actual_bid_chefs')\n",
    "# plt.scatter(md['mid_price'], obs['transportFees'])\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Arb 1: buy from chefs, sell to local\n",
    "mask1 = obs[\"actual_ask\"] < md[\"bid_price_1\"]\n",
    "print(f\"{np.sum(mask1)} opportunities for arb 1\")\n",
    "diff = md['bid_price_1'] - obs['actual_ask']\n",
    "profit = diff * md['bid_volume_1']\n",
    "profit = profit[mask1]\n",
    "print(f\"Max profit: {np.sum(profit)}\")\n",
    "print(np.mean(md['bid_volume_1'][mask1]))\n",
    "\n",
    "# Arb 2: buy from local, sell to chefs\n",
    "mask2 = obs[\"actual_bid\"] > md[\"ask_price_1\"]\n",
    "print(f\"{np.sum(mask2)} opportunities for arb 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c936401",
   "metadata": {},
   "source": [
    "I think I give up on price prediction at this point. There doesn't seem to be any predictive power in sunlight or sugar for price.  \n",
    "\n",
    "Macaron and sugar price move together (corr = 0.6) (which suggests cointegration) but tests show they aren't cointegrated. Maybe look at this again later.  \n",
    "\n",
    "Going back to the exchange arb that I found before, we can buy from chefs and sell to local. Theres quite few opportunities for this, netting only $4000 over 1e6 timestamps which is terrible, but what about buy/sell orders that come in?  \n",
    " \n",
    "Last year they said that there was a 'big taker of orchids', maybe there will be a bot that is a big taker of orchids but just isn't present in the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
